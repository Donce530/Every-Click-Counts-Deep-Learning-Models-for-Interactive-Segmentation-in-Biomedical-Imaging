{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import logging\n",
    "from copy import deepcopy\n",
    "from collections import defaultdict\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from isegm.utils.log import logger, TqdmToLogger, SummaryWriterAvg\n",
    "from isegm.utils.vis import draw_probmap, draw_points, add_tag\n",
    "from isegm.utils.misc import save_checkpoint\n",
    "from isegm.utils.serialization import get_config_repr\n",
    "from isegm.utils.distributed import get_dp_wrapper, get_sampler, reduce_loss_dict\n",
    "from torch.cuda.amp import autocast as autocast, GradScaler\n",
    "\n",
    "from isegm.utils.exp_imports.default import * \n",
    "\n",
    "MODEL_NAME = \"lidc_hrnet32\"\n",
    "\n",
    "from isegm.data.compose import ComposeDataset, ProportionalComposeDataset\n",
    "import torch.nn as nn\n",
    "from isegm.data.aligned_augmentation import AlignedAugmentator\n",
    "# from isegm.engine.focalclick_trainer import ISTrainer\n",
    "\n",
    "from isegm.data.compose import ComposeDataset, ProportionalComposeDataset\n",
    "import torch.nn as nn\n",
    "from isegm.data.aligned_augmentation import AlignedAugmentator\n",
    "# from isegm.engine.focalclick_trainer import ISTrainer\n",
    "from isegm.data.preprocess import Preprocessor\n",
    "from isegm.utils import exp\n",
    "from isegm.inference import utils\n",
    "\n",
    "cfg = exp.load_config_file('config.yml', return_edict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "points_sampler = MultiPointSampler(\n",
    "        24,\n",
    "        prob_gamma=0.80,\n",
    "        merge_objects_prob=0.15,\n",
    "        max_num_merged_objects=2,\n",
    "        use_hierarchy=False,\n",
    "        first_click_center=True,\n",
    "    )\n",
    "\n",
    "preprocessor = Preprocessor()\n",
    "\n",
    "dataset = utils.get_dataset('LIDC_2D_VAL', cfg, preprocessor=preprocessor)\n",
    "# dataset = utils.get_dataset('LIDC_CROPS_VAL', cfg, preprocessor=preprocessor)\n",
    "dataset.points_sampler = points_sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "def get_box_corners(mask):\n",
    "    mask = mask.astype(np.uint8)\n",
    "    mask[mask > 0] = 1\n",
    "    mask = mask.astype(np.uint8)\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    x, y, w, h = cv2.boundingRect(contours[0])\n",
    "    return x, y, x + w, y + h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "262144"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMAGE_HEIGHT, IMAGE_WIDTH = dataset.get_sample(0).image.shape[:2]\n",
    "PIXEL_COUNT = IMAGE_HEIGHT * IMAGE_WIDTH\n",
    "PIXEL_COUNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(538.078947368421, 16.789473684210527, 16.63157894736842)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "box_sizes = []\n",
    "widths = []\n",
    "heights = []\n",
    "\n",
    "for i in range(len(dataset)):\n",
    "# for i in range(int(len(dataset) * 0.15)):\n",
    "    sample = dataset.get_sample(i)\n",
    "    mask = sample.gt_mask\n",
    "    x1, y1, x2, y2 = get_box_corners(mask)\n",
    "    box_size = (x2 - x1) * (y2 - y1) * 1.5 # 1.5 as click is not expected to be on the mask \n",
    "    box_sizes.append(box_size)\n",
    "    widths.append(x2 - x1)\n",
    "    heights.append(y2 - y1)\n",
    "    \n",
    "mean_box_size = np.mean(box_sizes)\n",
    "mean_width = np.mean(widths)\n",
    "mean_height = np.mean(heights)\n",
    "mean_box_size, mean_width, mean_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.002052608289216694, 0.032791940789473686, 0.03248355263157895)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "box_percentage = mean_box_size / PIXEL_COUNT\n",
    "width_percentage = mean_width / IMAGE_WIDTH\n",
    "height_percentage = mean_height / IMAGE_HEIGHT\n",
    "box_percentage, width_percentage, height_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.032637746710526314"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_ratio = (width_percentage + height_percentage) / 2\n",
    "average_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.016, 0.049)\n",
      "*6:0.064 : 0.196\n",
      "x10.5:0.112 : 0.343\n"
     ]
    }
   ],
   "source": [
    "bounds = np.round(average_ratio * 0.5, 3), np.round(average_ratio * 1.5, 3)\n",
    "print(bounds)\n",
    "print(f'*6:{bounds[0] * 4} : {bounds[1] * 4}')\n",
    "print(f'x10.5:{bounds[0] * 7} : {bounds[1] * 7}')\n",
    "#LIDC 2D VAL: (0.015, 0.044)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.064, 0.196)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bounds[0]*4, bounds[1]*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
